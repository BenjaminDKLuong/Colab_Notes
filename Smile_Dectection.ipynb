{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smile_Dectection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminDKLuong/Colab_Notes/blob/master/Smile_Dectection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmM1aL8tJ4sL",
        "colab_type": "text"
      },
      "source": [
        "# Smile Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72P8LxP1Jqlu",
        "colab_type": "code",
        "outputId": "21bee7f6-77d9-415f-f245-301dd2473bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Real-World-Python-Deep-Learning-Projects.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Real-World-Python-Deep-Learning-Projects'...\n",
            "remote: Enumerating objects: 13503, done.\u001b[K\n",
            "remote: Total 13503 (delta 0), reused 0 (delta 0), pack-reused 13503\n",
            "Receiving objects: 100% (13503/13503), 178.97 MiB | 13.77 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "Checking out files: 100% (13472/13472), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oUmP3cKAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change working directory to new location\n",
        "import os\n",
        "os.chdir(\"/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXqbjjltKG_3",
        "colab_type": "code",
        "outputId": "71fe6d71-49d2-4a32-e9ab-897515c999bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# check current working directory\n",
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjtKyOcJKQOf",
        "colab_type": "text"
      },
      "source": [
        "## Data Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR7A-y-wW523",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba1b2c76-818c-450e-e0d4-d576bc901eff"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Prepare images to work with CNN model.\n",
        "\n",
        "Inspired by https://github.com/kylemcdonald/SmileCNN\n",
        "We're using data from https://github.com/hromi/SMILEsmileD/tree/master/SMILEs\n",
        "\n",
        "Download the repository as zip file and put SMILEs/negatives and SMILEs/positives\n",
        "into the data directory in the source direcotry for this section.\n",
        "\n",
        "Please install sckit-image package before\n",
        "using this script with:\n",
        "$ conda install scikit-image\n",
        "\"\"\"\n",
        "from os import listdir, path, remove\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.measure import block_reduce\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def img2array(f, detection=False, ii_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    Convert images into matrixes/two-dimensional arrays.\n",
        "\n",
        "    detection - if True we will resize an image to fit the\n",
        "                shape of a data that our first convolutional\n",
        "                layer is accepting which is 32x32 array,\n",
        "                used only on detection.\n",
        "\n",
        "    ii_size - this is the size that our input images have.\n",
        "    \"\"\"\n",
        "    rf=None\n",
        "    if detection:\n",
        "        rf=f.rsplit('.')\n",
        "        rf=rf[0]+'-resampled.'+rf[1]\n",
        "        im = Image.open(f)\n",
        "        # Create a smaller scalled down thumbnail\n",
        "        # of our image.\n",
        "        im.thumbnail(ii_size)\n",
        "        # Our thumbnail might not be of a perfect\n",
        "        # dimensions, so we need to create a new\n",
        "        # image and paste the thumbnail in.\n",
        "        newi = Image.new('L', ii_size)\n",
        "        newi.paste(im, (0,0))\n",
        "        newi.save(rf, \"JPEG\")\n",
        "        f=rf\n",
        "    # Turn images into an array.\n",
        "    data=imread(f, as_gray=True)\n",
        "    # Downsample it from 64x64 to 32x32\n",
        "    # (that's what we need to feed into our first convolutional layer).\n",
        "    data=block_reduce(data, block_size=(2, 2), func=np.mean)\n",
        "    if rf:\n",
        "        remove(rf)\n",
        "    return data\n",
        "\n",
        "def prep_array(data, detection=False):\n",
        "    \"\"\"\n",
        "    Convert our input array into the right format.\n",
        "\n",
        "    detection - if True we just wrapping up a single\n",
        "                image's array into a list to make things\n",
        "                consistent.\n",
        "    \"\"\"\n",
        "    if detection:\n",
        "        data=[data]\n",
        "    # By default values converted from our images\n",
        "    # are integers in range from 0 to 255 and our\n",
        "    # network will be really slow working with them.\n",
        "    # So, we need to convert them into values from\n",
        "    # 0.0 to 1.0 range which works much better in our case.\n",
        "    data=np.asarray(data) / 255.0\n",
        "    # We need to wrap each pixel value insided it's own array.\n",
        "    # This is the quick way of doing it.\n",
        "    data=np.expand_dims(data, axis=-1)\n",
        "    return data\n",
        "  \n",
        "    '''\n",
        "    prep_array turn \n",
        "\n",
        "    From This: \n",
        "    [[1 2 3]\n",
        "     [3 2 1]]\n",
        "\n",
        "    TO THIS:\n",
        "    [[[1]\n",
        "      [2]\n",
        "      [3]]\n",
        "\n",
        "     [[3]\n",
        "      [2]\n",
        "      [1]]]\n",
        "    '''\n",
        "  \n",
        "  \n",
        "  \n",
        "def load_data(data_directory):\n",
        "    \"\"\"\n",
        "    Go trough each image in a data directory,\n",
        "    convert it into an array, add into\n",
        "    our input array X and return it.\n",
        "    \"\"\"\n",
        "    X=[]\n",
        "    for filename in listdir(data_directory):\n",
        "        if not filename.endswith('.jpg'):\n",
        "            continue\n",
        "        p=path.join(data_directory, filename)\n",
        "        data=img2array(p)\n",
        "        X.append(data)\n",
        "    return prep_array(X)\n",
        "\n",
        "def gen_labels(length, label):\n",
        "    \"\"\"\n",
        "    Return a length list of label.\n",
        "    \"\"\"\n",
        "    return [ label for _ in range(length) ]\n",
        "\n",
        "def get_data():\n",
        "    \"\"\"\n",
        "    Generate X and Y arrays, inputs and classes\n",
        "    ready for use in our convolutional network.\n",
        "    \"\"\"\n",
        "    # Load images, generate labels, starting with negatives\n",
        "    x_neg = load_data('data/negatives/negatives7')\n",
        "    y_neg = gen_labels(len(x_neg), 0)\n",
        "\n",
        "    x_pos = load_data('data/positives/positives7')\n",
        "    y_pos = gen_labels(len(x_pos), 1)\n",
        "\n",
        "    # Merge negative and postive data into one.\n",
        "    X=np.concatenate([x_neg, x_pos])\n",
        "    Y=np.asarray(y_neg+y_pos)\n",
        "\n",
        "    # By default we will have 64 bit values,\n",
        "    # it will run quicker if we convert them into\n",
        "    # 32 bit.\n",
        "    X = X.astype(np.float32)\n",
        "    Y = Y.astype(np.int32)\n",
        "\n",
        "    # Get the dimensions and number of color channels\n",
        "    # that we have in our data.\n",
        "    # Here we have (32,32,1) which means 32x32 array with\n",
        "    # one color channel (because we have black and white images)\n",
        "    inputs=X.shape[1:]\n",
        "    # Number of classes we want to predict.\n",
        "    # 0 - not smiling, 1 - smiling.\n",
        "    classes=2\n",
        "    # Convert classes to vector, this is needed when we use\n",
        "    # softmax in the last layer.\n",
        "    Y = np_utils.to_categorical(Y, classes).astype(np.float32)\n",
        "\n",
        "    # Shuffle all the data because\n",
        "    # we have more negative samples\n",
        "    # than positive ones.\n",
        "    # Then keras will take care of\n",
        "    # spliting the data for us\n",
        "    # later on training.\n",
        "    ixes = np.arange(len(X))\n",
        "    np.random.shuffle(ixes)\n",
        "    X = X[ixes]\n",
        "    Y = Y[ixes]\n",
        "    return X, Y, inputs, classes\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_WLJaZ1W5U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "X, Y, inputs, classes=get_data()\n",
        "\n",
        "print('Inputs: %s' % repr(inputs))\n",
        "print('X[0] (first encoded image):')\n",
        "pprint(X[0])\n",
        "\n",
        "print('Y[0] (first encoded class):')\n",
        "pprint(Y[0])\n",
        "\n",
        "print('Classes %s' % classes)\n",
        "\n",
        "pprint(np_utils.to_categorical([0,1], classes).astype(np.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyqpAg5VPtbk",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz7ucycuKfb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Build, train and evaluate a CNN model for smile recognition.\n",
        "\"\"\"\n",
        "import conf\n",
        "from prep import get_data\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def get_smile_cnn(inputs=(32,32,1), classes=2):\n",
        "    \"\"\"\n",
        "    Define our CNN model for simple recognition.\n",
        "\n",
        "    inputs - a tupe of (rows, cols, channel) of our input arrays,\n",
        "             describing the \"shape\" of our data, we need to provide\n",
        "             it for the first Convolutional layer.\n",
        "\n",
        "    classes - a number of classes we want to predict, here we have\n",
        "              only two classes - 0 - not smiling, 1 - smiling.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    # X filters will create an X feature maps, the more we have\n",
        "    # the more \"features\" we can \"catch\".\n",
        "    # Kernel size is the size of a matrix that will extract\n",
        "    # our \"features\".\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=inputs))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "    # Factors by which to downscale and choose the maximum/most visible\n",
        "    # values.\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # % of neurons to ignore/help with making your model\n",
        "    # being more general, doing better on unseen data.\n",
        "    # 0.25 means 25%, try to comment out Dropout layers\n",
        "    # and see what happens...\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    # Adding a fully connected layer just before last layer\n",
        "    # help us learn the combinations of features from previous\n",
        "    # feature maps (results of Conv2D and MaxPooling2D layers).\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    # Same as comment above.\n",
        "    model.add(Dropout(0.5))\n",
        "    # Last layer is for classification, softmax allows us\n",
        "    # to recognize a few different classes.\n",
        "    model.add(Dense(classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "confs={'default': dict(model=get_smile_cnn)}\n",
        "\n",
        "def train_model(name, train_x, train_y, epochs, batches, inputs, classes):\n",
        "    \"\"\"\n",
        "    Compile and train model with choosen parameters.\n",
        "    \"\"\"\n",
        "    mparams=confs[name]\n",
        "    model=mparams['model']\n",
        "    model=model(inputs, classes)\n",
        "    # Compile model.\n",
        "    # We're using categorical_* and softmax function in the last\n",
        "    # layer to classify multiple classes.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # We're using 90% of data for training and 10% for validation/testing.\n",
        "    trs, tt=int(len(train_x)*0.90), int(len(train_x)*0.10)\n",
        "    train_x, train_y, test_x, test_y=train_x[0:trs], train_y[0:trs], train_x[-tt:], train_y[-tt:]\n",
        "    # Fit model on training data, validate during training on test data.\n",
        "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=epochs, batch_size=batches, verbose=2)\n",
        "    return model, name, mparams, train_x, train_y, test_x, test_y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4UVyudua0ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting our command line parameters\n",
        "name, epochs, batches, _=get_params()\n",
        "# Getting our images correctly converted\n",
        "# to the right format of arrays/matrices.\n",
        "train_x, train_y, inputs, classes=get_data()\n",
        "# Time for training!\n",
        "model, name, mp, train_x, train_y, test_x, test_y =train_model(name, train_x, train_y, epochs, batches, inputs, classes)\n",
        "# Save model to use for classification later on.\n",
        "mname='models/model-%s-%d-%d' % (name, epochs, batches)\n",
        "model.save(mname+'.h5')\n",
        "title='%s (epochs=%d, batch_size=%d)' % (name, epochs, batches)\n",
        "print('Evaluation for %s' % title)\n",
        "loss, acc = model.evaluate(train_x, train_y, verbose=2)\n",
        "print('Train accuracy: %.2f%%' % (acc*100))\n",
        "loss, acc = model.evaluate(test_x, test_y, verbose=2)\n",
        "print('Test accuracy: %.2f%%' % (acc*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FufBPfD9PwLg",
        "colab_type": "text"
      },
      "source": [
        "## Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZFYrARPKJnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}