{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smile_Dectection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminDKLuong/Colab_Notes/blob/master/Smile_Dectection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmM1aL8tJ4sL",
        "colab_type": "text"
      },
      "source": [
        "# Smile Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72P8LxP1Jqlu",
        "colab_type": "code",
        "outputId": "21bee7f6-77d9-415f-f245-301dd2473bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Real-World-Python-Deep-Learning-Projects.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Real-World-Python-Deep-Learning-Projects'...\n",
            "remote: Enumerating objects: 13503, done.\u001b[K\n",
            "remote: Total 13503 (delta 0), reused 0 (delta 0), pack-reused 13503\n",
            "Receiving objects: 100% (13503/13503), 178.97 MiB | 13.77 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "Checking out files: 100% (13472/13472), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oUmP3cKAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change working directory to new location\n",
        "import os\n",
        "os.chdir(\"/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXqbjjltKG_3",
        "colab_type": "code",
        "outputId": "71fe6d71-49d2-4a32-e9ab-897515c999bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check current working directory\n",
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjtKyOcJKQOf",
        "colab_type": "text"
      },
      "source": [
        "## Data Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H8QFqAlKffM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "9f4b4194-e125-4df1-a60a-e4fc8c8d5ac0"
      },
      "source": [
        "import numpy as np\n",
        "a = np.asarray([[1,2,3],[3,2,1]])\n",
        "print(a)\n",
        "data = np.expand_dims(a,axis=-1)\n",
        "print(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [3 2 1]]\n",
            "[[[1]\n",
            "  [2]\n",
            "  [3]]\n",
            "\n",
            " [[3]\n",
            "  [2]\n",
            "  [1]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR7A-y-wW523",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Prepare images to work with CNN model.\n",
        "\n",
        "Inspired by https://github.com/kylemcdonald/SmileCNN\n",
        "We're using data from https://github.com/hromi/SMILEsmileD/tree/master/SMILEs\n",
        "\n",
        "Download the repository as zip file and put SMILEs/negatives and SMILEs/positives\n",
        "into the data directory in the source direcotry for this section.\n",
        "\n",
        "Please install sckit-image package before\n",
        "using this script with:\n",
        "$ conda install scikit-image\n",
        "\"\"\"\n",
        "from os import listdir, path, remove\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.measure import block_reduce\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def img2array(f, detection=False, ii_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    Convert images into matrixes/two-dimensional arrays.\n",
        "\n",
        "    detection - if True we will resize an image to fit the\n",
        "                shape of a data that our first convolutional\n",
        "                layer is accepting which is 32x32 array,\n",
        "                used only on detection.\n",
        "\n",
        "    ii_size - this is the size that our input images have.\n",
        "    \"\"\"\n",
        "    rf=None\n",
        "    if detection:\n",
        "        rf=f.rsplit('.')\n",
        "        rf=rf[0]+'-resampled.'+rf[1]\n",
        "        im = Image.open(f)\n",
        "        # Create a smaller scalled down thumbnail\n",
        "        # of our image.\n",
        "        im.thumbnail(ii_size)\n",
        "        # Our thumbnail might not be of a perfect\n",
        "        # dimensions, so we need to create a new\n",
        "        # image and paste the thumbnail in.\n",
        "        newi = Image.new('L', ii_size)\n",
        "        newi.paste(im, (0,0))\n",
        "        newi.save(rf, \"JPEG\")\n",
        "        f=rf\n",
        "    # Turn images into an array.\n",
        "    data=imread(f, as_gray=True)\n",
        "    # Downsample it from 64x64 to 32x32\n",
        "    # (that's what we need to feed into our first convolutional layer).\n",
        "    data=block_reduce(data, block_size=(2, 2), func=np.mean)\n",
        "    if rf:\n",
        "        remove(rf)\n",
        "    return data\n",
        "\n",
        "def prep_array(data, detection=False):\n",
        "    \"\"\"\n",
        "    Convert our input array into the right format.\n",
        "\n",
        "    detection - if True we just wrapping up a single\n",
        "                image's array into a list to make things\n",
        "                consistent.\n",
        "    \"\"\"\n",
        "    if detection:\n",
        "        data=[data]\n",
        "    # By default values converted from our images\n",
        "    # are integers in range from 0 to 255 and our\n",
        "    # network will be really slow working with them.\n",
        "    # So, we need to convert them into values from\n",
        "    # 0.0 to 1.0 range which works much better in our case.\n",
        "    data=np.asarray(data) / 255.0\n",
        "    # We need to wrap each pixel value insided it's own array.\n",
        "    # This is the quick way of doing it.\n",
        "    data=np.expand_dims(data, axis=-1)\n",
        "    return data\n",
        "\n",
        "def load_data(data_directory):\n",
        "    \"\"\"\n",
        "    Go trough each image in a data directory,\n",
        "    convert it into an array, add into\n",
        "    our input array X and return it.\n",
        "    \"\"\"\n",
        "    X=[]\n",
        "    for filename in listdir(data_directory):\n",
        "        if not filename.endswith('.jpg'):\n",
        "            continue\n",
        "        p=path.join(data_directory, filename)\n",
        "        data=img2array(p)\n",
        "        X.append(data)\n",
        "    return prep_array(X)\n",
        "\n",
        "def gen_labels(length, label):\n",
        "    \"\"\"\n",
        "    Return a length list of label.\n",
        "    \"\"\"\n",
        "    return [ label for _ in range(length) ]\n",
        "\n",
        "def get_data():\n",
        "    \"\"\"\n",
        "    Generate X and Y arrays, inputs and classes\n",
        "    ready for use in our convolutional network.\n",
        "    \"\"\"\n",
        "    # Load images, generate labels, starting with negatives\n",
        "    x_neg = load_data('data/negatives/negatives7')\n",
        "    y_neg = gen_labels(len(x_neg), 0)\n",
        "\n",
        "    x_pos = load_data('data/positives/positives7')\n",
        "    y_pos = gen_labels(len(x_pos), 1)\n",
        "\n",
        "    # Merge negative and postive data into one.\n",
        "    X=np.concatenate([x_neg, x_pos])\n",
        "    Y=np.asarray(y_neg+y_pos)\n",
        "\n",
        "    # By default we will have 64 bit values,\n",
        "    # it will run quicker if we convert them into\n",
        "    # 32 bit.\n",
        "    X = X.astype(np.float32)\n",
        "    Y = Y.astype(np.int32)\n",
        "\n",
        "    # Get the dimensions and number of color channels\n",
        "    # that we have in our data.\n",
        "    # Here we have (32,32,1) which means 32x32 array with\n",
        "    # one color channel (because we have black and white images)\n",
        "    inputs=X.shape[1:]\n",
        "    # Number of classes we want to predict.\n",
        "    # 0 - not smiling, 1 - smiling.\n",
        "    classes=2\n",
        "    # Convert classes to vector, this is needed when we use\n",
        "    # softmax in the last layer.\n",
        "    Y = np_utils.to_categorical(Y, classes).astype(np.float32)\n",
        "\n",
        "    # Shuffle all the data because\n",
        "    # we have more negative samples\n",
        "    # than positive ones.\n",
        "    # Then keras will take care of\n",
        "    # spliting the data for us\n",
        "    # later on training.\n",
        "    ixes = np.arange(len(X))\n",
        "    np.random.shuffle(ixes)\n",
        "    X = X[ixes]\n",
        "    Y = Y[ixes]\n",
        "    return X, Y, inputs, classes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_WLJaZ1W5U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "X, Y, inputs, classes=get_data()\n",
        "print('Inputs: %s' % repr(inputs))\n",
        "print('X[0] (first encoded image):')\n",
        "pprint(X[0])\n",
        "print('Y[0] (first encoded class):')\n",
        "pprint(Y[0])\n",
        "print('Classes %s' % classes)\n",
        "pprint(np_utils.to_categorical([0,1], classes).astype(np.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyqpAg5VPtbk",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz7ucycuKfb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FufBPfD9PwLg",
        "colab_type": "text"
      },
      "source": [
        "## Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZFYrARPKJnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}