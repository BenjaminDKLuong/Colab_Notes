{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smile_Dectection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminDKLuong/Colab_Notes/blob/master/Smile_Dectection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmM1aL8tJ4sL",
        "colab_type": "text"
      },
      "source": [
        "# Smile Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72P8LxP1Jqlu",
        "colab_type": "code",
        "outputId": "7bbff4e6-91a7-4683-a3cb-4748701378e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Real-World-Python-Deep-Learning-Projects.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Real-World-Python-Deep-Learning-Projects'...\n",
            "remote: Enumerating objects: 13503, done.\u001b[K\n",
            "remote: Total 13503 (delta 0), reused 0 (delta 0), pack-reused 13503\u001b[K\n",
            "Receiving objects: 100% (13503/13503), 178.97 MiB | 23.81 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "Checking out files: 100% (13472/13472), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oUmP3cKAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change working directory to new location\n",
        "import os\n",
        "os.chdir(\"/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXqbjjltKG_3",
        "colab_type": "code",
        "outputId": "5892fe37-0693-49c1-d6d1-6f22fe19cd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# check current working directory\n",
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjtKyOcJKQOf",
        "colab_type": "text"
      },
      "source": [
        "## Data Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR7A-y-wW523",
        "colab_type": "code",
        "outputId": "c7d6b443-a40e-4ad2-deba-556476dfe450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Prepare images to work with CNN model.\n",
        "\n",
        "Inspired by https://github.com/kylemcdonald/SmileCNN\n",
        "We're using data from https://github.com/hromi/SMILEsmileD/tree/master/SMILEs\n",
        "\n",
        "Download the repository as zip file and put SMILEs/negatives and SMILEs/positives\n",
        "into the data directory in the source direcotry for this section.\n",
        "\n",
        "Please install sckit-image package before\n",
        "using this script with:\n",
        "$ conda install scikit-image\n",
        "\"\"\"\n",
        "from os import listdir, path, remove\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.measure import block_reduce\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def img2array(f, detection=False, ii_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    Convert images into matrixes/two-dimensional arrays.\n",
        "\n",
        "    detection - if True we will resize an image to fit the\n",
        "                shape of a data that our first convolutional\n",
        "                layer is accepting which is 32x32 array,\n",
        "                used only on detection.\n",
        "\n",
        "    ii_size - this is the size that our input images have.\n",
        "    \"\"\"\n",
        "    rf=None\n",
        "    if detection:\n",
        "        rf=f.rsplit('.')\n",
        "        rf=rf[0]+'-resampled.'+rf[1]\n",
        "        im = Image.open(f)\n",
        "        # Create a smaller scalled down thumbnail\n",
        "        # of our image.\n",
        "        im.thumbnail(ii_size)\n",
        "        # Our thumbnail might not be of a perfect\n",
        "        # dimensions, so we need to create a new\n",
        "        # image and paste the thumbnail in.\n",
        "        newi = Image.new('L', ii_size)\n",
        "        newi.paste(im, (0,0))\n",
        "        newi.save(rf, \"JPEG\")\n",
        "        f=rf\n",
        "    # Turn images into an array.\n",
        "    data=imread(f, as_gray=True)\n",
        "    # Downsample it from 64x64 to 32x32\n",
        "    # (that's what we need to feed into our first convolutional layer).\n",
        "    data=block_reduce(data, block_size=(2, 2), func=np.mean)\n",
        "    if rf:\n",
        "        remove(rf)\n",
        "    return data\n",
        "\n",
        "def prep_array(data, detection=False):\n",
        "    \"\"\"\n",
        "    Convert our input array into the right format.\n",
        "\n",
        "    detection - if True we just wrapping up a single\n",
        "                image's array into a list to make things\n",
        "                consistent.\n",
        "    \"\"\"\n",
        "    if detection:\n",
        "        data=[data]\n",
        "    # By default values converted from our images\n",
        "    # are integers in range from 0 to 255 and our\n",
        "    # network will be really slow working with them.\n",
        "    # So, we need to convert them into values from\n",
        "    # 0.0 to 1.0 range which works much better in our case.\n",
        "    data=np.asarray(data) / 255.0\n",
        "    # We need to wrap each pixel value insided it's own array.\n",
        "    # This is the quick way of doing it.\n",
        "    data=np.expand_dims(data, axis=-1)\n",
        "    return data\n",
        "  \n",
        "    '''\n",
        "    prep_array turn \n",
        "\n",
        "    From This: \n",
        "    [[1 2 3]\n",
        "     [3 2 1]]\n",
        "\n",
        "    TO THIS:\n",
        "    [[[1]\n",
        "      [2]\n",
        "      [3]]\n",
        "\n",
        "     [[3]\n",
        "      [2]\n",
        "      [1]]]\n",
        "    '''\n",
        "  \n",
        "  \n",
        "  \n",
        "def load_data(data_directory):\n",
        "    \"\"\"\n",
        "    Go trough each image in a data directory,\n",
        "    convert it into an array, add into\n",
        "    our input array X and return it.\n",
        "    \"\"\"\n",
        "    X=[]\n",
        "    for filename in listdir(data_directory):\n",
        "        if not filename.endswith('.jpg'):\n",
        "            continue\n",
        "        p=path.join(data_directory, filename)\n",
        "        data=img2array(p)\n",
        "        X.append(data)\n",
        "    return prep_array(X)\n",
        "\n",
        "def gen_labels(length, label):\n",
        "    \"\"\"\n",
        "    Return a length list of label.\n",
        "    \"\"\"\n",
        "    return [ label for _ in range(length) ]\n",
        "\n",
        "def get_data():\n",
        "    \"\"\"\n",
        "    Generate X and Y arrays, inputs and classes\n",
        "    ready for use in our convolutional network.\n",
        "    \"\"\"\n",
        "    # Load images, generate labels, starting with negatives\n",
        "    x_neg = load_data('data/negatives/negatives7')\n",
        "    y_neg = gen_labels(len(x_neg), 0)\n",
        "\n",
        "    x_pos = load_data('data/positives/positives7')\n",
        "    y_pos = gen_labels(len(x_pos), 1)\n",
        "\n",
        "    # Merge negative and postive data into one.\n",
        "    X=np.concatenate([x_neg, x_pos])\n",
        "    Y=np.asarray(y_neg+y_pos)\n",
        "\n",
        "    # By default we will have 64 bit values,\n",
        "    # it will run quicker if we convert them into\n",
        "    # 32 bit.\n",
        "    X = X.astype(np.float32)\n",
        "    Y = Y.astype(np.int32)\n",
        "\n",
        "    # Get the dimensions and number of color channels\n",
        "    # that we have in our data.\n",
        "    # Here we have (32,32,1) which means 32x32 array with\n",
        "    # one color channel (because we have black and white images)\n",
        "    inputs=X.shape[1:]\n",
        "    # Number of classes we want to predict.\n",
        "    # 0 - not smiling, 1 - smiling.\n",
        "    classes=2\n",
        "    # Convert classes to vector, this is needed when we use\n",
        "    # softmax in the last layer.\n",
        "    Y = np_utils.to_categorical(Y, classes).astype(np.float32)\n",
        "\n",
        "    # Shuffle all the data because\n",
        "    # we have more negative samples\n",
        "    # than positive ones.\n",
        "    # Then keras will take care of\n",
        "    # spliting the data for us\n",
        "    # later on training.\n",
        "    ixes = np.arange(len(X))\n",
        "    np.random.shuffle(ixes)\n",
        "    X = X[ixes]\n",
        "    Y = Y[ixes]\n",
        "    return X, Y, inputs, classes\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_WLJaZ1W5U1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1012
        },
        "outputId": "d3a1326c-3421-4314-99df-dced54054e23"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "X, Y, inputs, classes=get_data()\n",
        "\n",
        "print('Inputs: %s' % repr(inputs))\n",
        "\n",
        "print('X[0] (first encoded image):')\n",
        "pprint(X[0])\n",
        "\n",
        "print('Y[0] (first encoded class):')\n",
        "pprint(Y[0])\n",
        "\n",
        "print('Classes %s' % classes)\n",
        "\n",
        "pprint(np_utils.to_categorical([0,1], classes).astype(np.float32))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: (32, 32, 1)\n",
            "X[0] (first encoded image):\n",
            "array([[[0.20196079],\n",
            "        [0.17843138],\n",
            "        [0.2647059 ],\n",
            "        ...,\n",
            "        [0.6117647 ],\n",
            "        [0.65      ],\n",
            "        [0.18921569]],\n",
            "\n",
            "       [[0.23627451],\n",
            "        [0.31764707],\n",
            "        [0.40882352],\n",
            "        ...,\n",
            "        [0.5882353 ],\n",
            "        [0.5921569 ],\n",
            "        [0.15882353]],\n",
            "\n",
            "       [[0.42352942],\n",
            "        [0.46960783],\n",
            "        [0.45784312],\n",
            "        ...,\n",
            "        [0.59411764],\n",
            "        [0.5862745 ],\n",
            "        [0.15686275]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0.7921569 ],\n",
            "        [0.6970588 ],\n",
            "        [0.3647059 ],\n",
            "        ...,\n",
            "        [0.12843138],\n",
            "        [0.17352942],\n",
            "        [0.1882353 ]],\n",
            "\n",
            "       [[0.6764706 ],\n",
            "        [0.89117646],\n",
            "        [0.5176471 ],\n",
            "        ...,\n",
            "        [0.11960784],\n",
            "        [0.17352942],\n",
            "        [0.21568628]],\n",
            "\n",
            "       [[0.52156866],\n",
            "        [0.9245098 ],\n",
            "        [0.65686274],\n",
            "        ...,\n",
            "        [0.1254902 ],\n",
            "        [0.17941177],\n",
            "        [0.19901961]]], dtype=float32)\n",
            "Y[0] (first encoded class):\n",
            "array([1., 0.], dtype=float32)\n",
            "Classes 2\n",
            "array([[1., 0.],\n",
            "       [0., 1.]], dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyqpAg5VPtbk",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz7ucycuKfb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Build, train and evaluate a CNN model for smile recognition.\n",
        "\"\"\"\n",
        "import conf\n",
        "from prep import get_data\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def get_smile_cnn(inputs=(32,32,1), classes=2):\n",
        "    \"\"\"\n",
        "    Define our CNN model for simple recognition.\n",
        "\n",
        "    inputs - a tupe of (rows, cols, channel) of our input arrays,\n",
        "             describing the \"shape\" of our data, we need to provide\n",
        "             it for the first Convolutional layer.\n",
        "\n",
        "    classes - a number of classes we want to predict, here we have\n",
        "              only two classes - 0 - not smiling, 1 - smiling.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    # X filters will create an X feature maps, the more we have\n",
        "    # the more \"features\" we can \"catch\".\n",
        "    # Kernel size is the size of a matrix that will extract\n",
        "    # our \"features\".\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=inputs))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "    # Factors by which to downscale and choose the maximum/most visible\n",
        "    # values.\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # % of neurons to ignore/help with making your model\n",
        "    # being more general, doing better on unseen data.\n",
        "    # 0.25 means 25%, try to comment out Dropout layers\n",
        "    # and see what happens...\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    # Adding a fully connected layer just before last layer\n",
        "    # help us learn the combinations of features from previous\n",
        "    # feature maps (results of Conv2D and MaxPooling2D layers).\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    # Same as comment above.\n",
        "    model.add(Dropout(0.5))\n",
        "    # Last layer is for classification, softmax allows us\n",
        "    # to recognize a few different classes.\n",
        "    model.add(Dense(classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "confs={'default': dict(model=get_smile_cnn)}\n",
        "\n",
        "def train_model(name, train_x, train_y, epochs, batches, inputs, classes):\n",
        "    \"\"\"\n",
        "    Compile and train model with choosen parameters.\n",
        "    \"\"\"\n",
        "    mparams=confs[name]\n",
        "    model=mparams['model']\n",
        "    model=model(inputs, classes)\n",
        "    \n",
        "    # Compile model.\n",
        "    # We're using categorical_* and softmax function in the last\n",
        "    # layer to classify multiple classes.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # We're using 90% of data for training and 10% for validation/testing.\n",
        "    trs, tt=int(len(train_x)*0.90), int(len(train_x)*0.10)\n",
        "    train_x, train_y, test_x, test_y=train_x[0:trs], train_y[0:trs], train_x[-tt:], train_y[-tt:]\n",
        "    \n",
        "    # Fit model on training data, validate during training on test data.\n",
        "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=epochs, batch_size=batches, verbose=2)\n",
        "    return model, name, mparams, train_x, train_y, test_x, test_y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4UVyudua0ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "7169540f-4941-4b8a-d47d-9b9cd2a36130"
      },
      "source": [
        "# Getting our command line parameters\n",
        "name = 'default'\n",
        "epochs = 15\n",
        "batches= 32\n",
        "\n",
        "\n",
        "# Time for training!\n",
        "model, name, mp, train_x, train_y, test_x, test_y =train_model(name, X, Y, epochs, batches, inputs, classes)\n",
        "\n",
        "# Save model to use for classification later on.\n",
        "mname='models/model-%s-%d-%d' % (name, epochs, batches)\n",
        "model.save(mname+'.h5')\n",
        "\n",
        "title='%s (epochs=%d, batch_size=%d)' % (name, epochs, batches)\n",
        "print('Evaluation for %s' % title)\n",
        "\n",
        "loss, acc = model.evaluate(train_x, train_y, verbose=2)\n",
        "print('Train accuracy: %.2f%%' % (acc*100))\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y, verbose=2)\n",
        "print('Test accuracy: %.2f%%' % (acc*100))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 11849 samples, validate on 1316 samples\n",
            "Epoch 1/15\n",
            " - 6s - loss: 0.4176 - acc: 0.8085 - val_loss: 0.3029 - val_acc: 0.8822\n",
            "Epoch 2/15\n",
            " - 2s - loss: 0.2974 - acc: 0.8787 - val_loss: 0.2611 - val_acc: 0.8853\n",
            "Epoch 3/15\n",
            " - 2s - loss: 0.2655 - acc: 0.8963 - val_loss: 0.2357 - val_acc: 0.8989\n",
            "Epoch 4/15\n",
            " - 2s - loss: 0.2461 - acc: 0.9044 - val_loss: 0.2246 - val_acc: 0.9020\n",
            "Epoch 5/15\n",
            " - 2s - loss: 0.2294 - acc: 0.9132 - val_loss: 0.2134 - val_acc: 0.9081\n",
            "Epoch 6/15\n",
            " - 2s - loss: 0.2164 - acc: 0.9168 - val_loss: 0.2157 - val_acc: 0.9119\n",
            "Epoch 7/15\n",
            " - 2s - loss: 0.2069 - acc: 0.9223 - val_loss: 0.2109 - val_acc: 0.9149\n",
            "Epoch 8/15\n",
            " - 2s - loss: 0.1977 - acc: 0.9228 - val_loss: 0.2136 - val_acc: 0.9103\n",
            "Epoch 9/15\n",
            " - 2s - loss: 0.1896 - acc: 0.9276 - val_loss: 0.1949 - val_acc: 0.9157\n",
            "Epoch 10/15\n",
            " - 2s - loss: 0.1767 - acc: 0.9303 - val_loss: 0.1972 - val_acc: 0.9164\n",
            "Epoch 11/15\n",
            " - 2s - loss: 0.1718 - acc: 0.9358 - val_loss: 0.1899 - val_acc: 0.9210\n",
            "Epoch 12/15\n",
            " - 2s - loss: 0.1617 - acc: 0.9361 - val_loss: 0.1844 - val_acc: 0.9240\n",
            "Epoch 13/15\n",
            " - 2s - loss: 0.1574 - acc: 0.9390 - val_loss: 0.1937 - val_acc: 0.9248\n",
            "Epoch 14/15\n",
            " - 2s - loss: 0.1453 - acc: 0.9440 - val_loss: 0.1959 - val_acc: 0.9240\n",
            "Epoch 15/15\n",
            " - 2s - loss: 0.1348 - acc: 0.9476 - val_loss: 0.1895 - val_acc: 0.9217\n",
            "Evaluation for default (epochs=15, batch_size=32)\n",
            "Train accuracy: 96.94%\n",
            "Test accuracy: 92.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FufBPfD9PwLg",
        "colab_type": "text"
      },
      "source": [
        "## Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZFYrARPKJnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD MODEL\n",
        "from keras.models import load_model\n",
        "\n",
        "name = 'default'\n",
        "epochs = 15\n",
        "batches= 32\n",
        "\n",
        "mname='models/model-%s-%d-%d' % (name, epochs, batches)\n",
        "model_file = mname+'.h5'\n",
        "\n",
        "if os.path.exists(model_file):\n",
        "    model=load_model(model_file)\n",
        "else:\n",
        "    print(\"Can't find %s model, train it first using 'train.py %s %d %d'\" % (mname, name, epochs, batches))\n",
        "    exit(1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL07psK3kw82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image path\n",
        "filename= '/content/Real-World-Python-Deep-Learning-Projects/Section 4 Code/source/data/new_samples/1-ns.jpg'\n",
        "# convert input images\n",
        "img_data = prep_array(img2array(filename, detection=True), detection=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-kVdY8FnzsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e8e0f355-a0b5-4625-9655-5291ce8ddf06"
      },
      "source": [
        "# predict using the model\n",
        "pc=model.predict_classes(img_data)\n",
        "pc=pc[0]\n",
        "# Here the probablity for each class.\n",
        "prob=model.predict_proba(img_data)\n",
        "prob=prob[0]\n",
        "# If our prediction doesn't match file's mark (0/-ns for no smile, 1/-s for smile)\n",
        "# mark it with star for examiation.\n",
        "fname=filename.split('/')[-1]\n",
        "if pc==0:\n",
        "    print('I think this person is NOT SMILING (%.2f%% sure)' % (prob[0]*100))\n",
        "    if '-ns' in fname:\n",
        "      print(\"The prediction is CORRECT\")\n",
        "    else:\n",
        "      print(\"The prediction is NOT CORRECT\")\n",
        "if pc==1:\n",
        "    print('I think this person is SMILING (%.2f%% sure)' % (prob[1]*100))\n",
        "    if '-ns' in fname:\n",
        "      print(\"The prediction is CORRECT\")\n",
        "    else:\n",
        "      print(\"The prediction is NOT CORRECT\")\n",
        "#print(filename, '\\n%s (%.2f%% of smile(1/-s), %.2f%% of no smile(0/-ns))' % (fmark, prob[1]*100, prob[0]*100))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I think this person is NOT SMILING (98.38% sure)\n",
            "The prediction is CORRECT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUe5fIM1qsT3",
        "colab_type": "text"
      },
      "source": [
        "## Input Image Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGMFaMKDqIgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a1b630ae-9ca5-4698-9957-07c26d5119db"
      },
      "source": [
        "# importing matplotlib modules \n",
        "import matplotlib.image as mpimg \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "# Read Images \n",
        "img = mpimg.imread(filename) \n",
        "  \n",
        "# Output Images \n",
        "plt.imshow(img) \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f39c3108eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOYAAAD8CAYAAABjJ9hGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5xMuzeCqaNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}