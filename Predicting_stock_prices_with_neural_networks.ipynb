{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting_stock_prices_with_neural_networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminDKLuong/Colab_Notes/blob/master/Predicting_stock_prices_with_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91tYYzOuMzMk",
        "colab_type": "text"
      },
      "source": [
        "# Predicting stock prices with neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpgtn4Cv4w5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1c3714af-9ab0-4dae-cc17-f3955e932cf1"
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Python-Deep-Learning-Solutions-.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Python-Deep-Learning-Solutions-'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 175 (delta 0), reused 0 (delta 0), pack-reused 166\u001b[K\n",
            "Receiving objects: 100% (175/175), 18.61 MiB | 30.88 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2JL2g6SNHD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change working directory to new location\n",
        "import os\n",
        "os.chdir(\"/content/Python-Deep-Learning-Solutions-/Section05\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Hfg0a2NHtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85e111b2-d202-4d50-ee86-acb414212d33"
      },
      "source": [
        "# check current working directory\n",
        "%pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Python-Deep-Learning-Solutions-/Section05'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dEVEIGSOzaE",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iMajWHSNHk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d578685-5e18-44b6-fef3-ae503383e45e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY64GzENO7jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "01aa17f5-b0f6-40cd-8407-8fbb92159e82"
      },
      "source": [
        "data = pd.read_csv('Data/stock-data.csv')\n",
        "# Reorder the columns for convenience\n",
        "data = data[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3471.949951</td>\n",
              "      <td>4073.729980</td>\n",
              "      <td>3459.850098</td>\n",
              "      <td>33352380000</td>\n",
              "      <td>3966.110107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3950.590088</td>\n",
              "      <td>4289.060059</td>\n",
              "      <td>3615.790039</td>\n",
              "      <td>30916110000</td>\n",
              "      <td>3766.989990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3760.949951</td>\n",
              "      <td>4208.729980</td>\n",
              "      <td>3521.139893</td>\n",
              "      <td>33222920000</td>\n",
              "      <td>4206.350098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4252.149902</td>\n",
              "      <td>4259.870117</td>\n",
              "      <td>3614.659912</td>\n",
              "      <td>34727330000</td>\n",
              "      <td>3672.820068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3714.479980</td>\n",
              "      <td>3714.479980</td>\n",
              "      <td>3026.110107</td>\n",
              "      <td>44129010000</td>\n",
              "      <td>3369.629883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Open         High          Low       Volume        Close\n",
              "0  3471.949951  4073.729980  3459.850098  33352380000  3966.110107\n",
              "1  3950.590088  4289.060059  3615.790039  30916110000  3766.989990\n",
              "2  3760.949951  4208.729980  3521.139893  33222920000  4206.350098\n",
              "3  4252.149902  4259.870117  3614.659912  34727330000  3672.820068\n",
              "4  3714.479980  3714.479980  3026.110107  44129010000  3369.629883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6E0c5I3O7gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 21 # 20 preceeding inputs\n",
        "n_features = len(data.columns)\n",
        "val_ratio = 0.1\n",
        "n_epochs = 300\n",
        "batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlt9Pkt6O7de",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c1fc3ada-b43f-44be-b6ab-cc7738f25358"
      },
      "source": [
        "data = data.as_matrix()\n",
        "data_processed = []\n",
        "for index in range(len(data) - sequence_length):\n",
        "    data_processed.append(data[index : index + sequence_length])\n",
        "data_processed = np.array(data_processed)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk8Fj-zcO7am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "26fc53ff-5ab7-434d-9b2d-e2f7956d789d"
      },
      "source": [
        "val_split = round((1-val_ratio) * data_processed.shape[0])\n",
        "train = data_processed[: int(val_split), :]\n",
        "val = data_processed[int(val_split) :, :]\n",
        "\n",
        "print('Training data: {}'.format(train.shape))\n",
        "print('Validation data: {}'.format(val.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: (165, 21, 5)\n",
            "Validation data: (18, 21, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8_B0fbRO7Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8c4a4a35-5f8a-401b-ca53-f8acea52c6ec"
      },
      "source": [
        "train_samples, train_nx, train_ny = train.shape\n",
        "val_samples, val_nx, val_ny = val.shape\n",
        "\n",
        "train = train.reshape((train_samples, train_nx * train_ny))\n",
        "val = val.reshape((val_samples, val_nx * val_ny))\n",
        "\n",
        "print('Training data: {}'.format(train.shape))\n",
        "print('Validation data: {}'.format(val.shape))\n",
        "print()\n",
        "\n",
        "# convert input to [0,1]\n",
        "preprocessor = MinMaxScaler().fit(train)\n",
        "train = preprocessor.transform(train)\n",
        "val = preprocessor.transform(val)\n",
        "\n",
        "train = train.reshape((train_samples, train_nx, train_ny))\n",
        "val = val.reshape((val_samples, val_nx, val_ny))\n",
        "\n",
        "print('Training data: {}'.format(train.shape))\n",
        "print('Validation data: {}'.format(val.shape))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: (165, 105)\n",
            "Validation data: (18, 105)\n",
            "\n",
            "Training data: (165, 21, 5)\n",
            "Validation data: (18, 21, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6o08o9ENHew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3a14eed-3089-4b9f-ab04-0d1fee2f46a2"
      },
      "source": [
        "train[:, : -1].shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165, 20, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlGis_etP8mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0007d7d6-6b41-427f-fa90-c0555cd08920"
      },
      "source": [
        "train[:, -1][: ,-1].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JJ9aap7NHhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[:, : -1] #left out the last row\n",
        "y_train = train[:, -1][: ,-1] # select the last row, then select last number of that\n",
        "\n",
        "X_val = val[:, : -1]\n",
        "y_val = val[:, -1][ : ,-1]\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], n_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEUxqGoUQfbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9583de-e6e8-4731-d20b-60ace29daac2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165, 20, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8MIyhWiRgqu",
        "colab_type": "text"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dOC0-_QkfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "d3956d47-7b2f-402c-df5e-a24962d83a26"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(input_shape=(X_train.shape[1:]), units = 128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units=1))\n",
        "model.add(Activation(\"linear\"))\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN8kC21zQkcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10756
        },
        "outputId": "12950bfa-d66a-4bfb-cc65-aae1fdb54675"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=n_epochs,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/300\n",
            "165/165 [==============================] - 3s 21ms/step - loss: 0.2080\n",
            "Epoch 2/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.1033\n",
            "Epoch 3/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0390\n",
            "Epoch 4/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0119\n",
            "Epoch 5/300\n",
            "165/165 [==============================] - 0s 377us/step - loss: 0.0355\n",
            "Epoch 6/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0412\n",
            "Epoch 7/300\n",
            "165/165 [==============================] - 0s 359us/step - loss: 0.0228\n",
            "Epoch 8/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0112\n",
            "Epoch 9/300\n",
            "165/165 [==============================] - 0s 349us/step - loss: 0.0092\n",
            "Epoch 10/300\n",
            "165/165 [==============================] - 0s 411us/step - loss: 0.0146\n",
            "Epoch 11/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0172\n",
            "Epoch 12/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0189\n",
            "Epoch 13/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0171\n",
            "Epoch 14/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0161\n",
            "Epoch 15/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0100\n",
            "Epoch 16/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0070\n",
            "Epoch 17/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0065\n",
            "Epoch 18/300\n",
            "165/165 [==============================] - 0s 354us/step - loss: 0.0085\n",
            "Epoch 19/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0106\n",
            "Epoch 20/300\n",
            "165/165 [==============================] - 0s 379us/step - loss: 0.0106\n",
            "Epoch 21/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0091\n",
            "Epoch 22/300\n",
            "165/165 [==============================] - 0s 411us/step - loss: 0.0099\n",
            "Epoch 23/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0069\n",
            "Epoch 24/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0056\n",
            "Epoch 25/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0064\n",
            "Epoch 26/300\n",
            "165/165 [==============================] - 0s 450us/step - loss: 0.0066\n",
            "Epoch 27/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0097\n",
            "Epoch 28/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0093\n",
            "Epoch 29/300\n",
            "165/165 [==============================] - 0s 393us/step - loss: 0.0073\n",
            "Epoch 30/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0073\n",
            "Epoch 31/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0062\n",
            "Epoch 32/300\n",
            "165/165 [==============================] - 0s 351us/step - loss: 0.0063\n",
            "Epoch 33/300\n",
            "165/165 [==============================] - 0s 377us/step - loss: 0.0054\n",
            "Epoch 34/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0073\n",
            "Epoch 35/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0065\n",
            "Epoch 36/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0063\n",
            "Epoch 37/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0063\n",
            "Epoch 38/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0070\n",
            "Epoch 39/300\n",
            "165/165 [==============================] - 0s 376us/step - loss: 0.0060\n",
            "Epoch 40/300\n",
            "165/165 [==============================] - 0s 368us/step - loss: 0.0050\n",
            "Epoch 41/300\n",
            "165/165 [==============================] - 0s 353us/step - loss: 0.0062\n",
            "Epoch 42/300\n",
            "165/165 [==============================] - 0s 413us/step - loss: 0.0049\n",
            "Epoch 43/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0059\n",
            "Epoch 44/300\n",
            "165/165 [==============================] - 0s 384us/step - loss: 0.0062\n",
            "Epoch 45/300\n",
            "165/165 [==============================] - 0s 360us/step - loss: 0.0058\n",
            "Epoch 46/300\n",
            "165/165 [==============================] - 0s 367us/step - loss: 0.0062\n",
            "Epoch 47/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0054\n",
            "Epoch 48/300\n",
            "165/165 [==============================] - 0s 372us/step - loss: 0.0051\n",
            "Epoch 49/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0054\n",
            "Epoch 50/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0059\n",
            "Epoch 51/300\n",
            "165/165 [==============================] - 0s 369us/step - loss: 0.0059\n",
            "Epoch 52/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0057\n",
            "Epoch 53/300\n",
            "165/165 [==============================] - 0s 365us/step - loss: 0.0056\n",
            "Epoch 54/300\n",
            "165/165 [==============================] - 0s 396us/step - loss: 0.0048\n",
            "Epoch 55/300\n",
            "165/165 [==============================] - 0s 435us/step - loss: 0.0051\n",
            "Epoch 56/300\n",
            "165/165 [==============================] - 0s 453us/step - loss: 0.0044\n",
            "Epoch 57/300\n",
            "165/165 [==============================] - 0s 396us/step - loss: 0.0052\n",
            "Epoch 58/300\n",
            "165/165 [==============================] - 0s 480us/step - loss: 0.0062\n",
            "Epoch 59/300\n",
            "165/165 [==============================] - 0s 427us/step - loss: 0.0061\n",
            "Epoch 60/300\n",
            "165/165 [==============================] - 0s 449us/step - loss: 0.0056\n",
            "Epoch 61/300\n",
            "165/165 [==============================] - 0s 440us/step - loss: 0.0054\n",
            "Epoch 62/300\n",
            "165/165 [==============================] - 0s 437us/step - loss: 0.0047\n",
            "Epoch 63/300\n",
            "165/165 [==============================] - 0s 416us/step - loss: 0.0058\n",
            "Epoch 64/300\n",
            "165/165 [==============================] - 0s 412us/step - loss: 0.0050\n",
            "Epoch 65/300\n",
            "165/165 [==============================] - 0s 403us/step - loss: 0.0060\n",
            "Epoch 66/300\n",
            "165/165 [==============================] - 0s 397us/step - loss: 0.0049\n",
            "Epoch 67/300\n",
            "165/165 [==============================] - 0s 396us/step - loss: 0.0049\n",
            "Epoch 68/300\n",
            "165/165 [==============================] - 0s 423us/step - loss: 0.0053\n",
            "Epoch 69/300\n",
            "165/165 [==============================] - 0s 412us/step - loss: 0.0041\n",
            "Epoch 70/300\n",
            "165/165 [==============================] - 0s 414us/step - loss: 0.0053\n",
            "Epoch 71/300\n",
            "165/165 [==============================] - 0s 407us/step - loss: 0.0051\n",
            "Epoch 72/300\n",
            "165/165 [==============================] - 0s 414us/step - loss: 0.0047\n",
            "Epoch 73/300\n",
            "165/165 [==============================] - 0s 504us/step - loss: 0.0048\n",
            "Epoch 74/300\n",
            "165/165 [==============================] - 0s 420us/step - loss: 0.0053\n",
            "Epoch 75/300\n",
            "165/165 [==============================] - 0s 423us/step - loss: 0.0058\n",
            "Epoch 76/300\n",
            "165/165 [==============================] - 0s 422us/step - loss: 0.0047\n",
            "Epoch 77/300\n",
            "165/165 [==============================] - 0s 405us/step - loss: 0.0054\n",
            "Epoch 78/300\n",
            "165/165 [==============================] - 0s 420us/step - loss: 0.0060\n",
            "Epoch 79/300\n",
            "165/165 [==============================] - 0s 425us/step - loss: 0.0048\n",
            "Epoch 80/300\n",
            "165/165 [==============================] - 0s 418us/step - loss: 0.0043\n",
            "Epoch 81/300\n",
            "165/165 [==============================] - 0s 404us/step - loss: 0.0042\n",
            "Epoch 82/300\n",
            "165/165 [==============================] - 0s 413us/step - loss: 0.0049\n",
            "Epoch 83/300\n",
            "165/165 [==============================] - 0s 404us/step - loss: 0.0050\n",
            "Epoch 84/300\n",
            "165/165 [==============================] - 0s 384us/step - loss: 0.0052\n",
            "Epoch 85/300\n",
            "165/165 [==============================] - 0s 410us/step - loss: 0.0054\n",
            "Epoch 86/300\n",
            "165/165 [==============================] - 0s 428us/step - loss: 0.0043\n",
            "Epoch 87/300\n",
            "165/165 [==============================] - 0s 459us/step - loss: 0.0050\n",
            "Epoch 88/300\n",
            "165/165 [==============================] - 0s 402us/step - loss: 0.0045\n",
            "Epoch 89/300\n",
            "165/165 [==============================] - 0s 418us/step - loss: 0.0050\n",
            "Epoch 90/300\n",
            "165/165 [==============================] - 0s 399us/step - loss: 0.0047\n",
            "Epoch 91/300\n",
            "165/165 [==============================] - 0s 396us/step - loss: 0.0055\n",
            "Epoch 92/300\n",
            "165/165 [==============================] - 0s 393us/step - loss: 0.0055\n",
            "Epoch 93/300\n",
            "165/165 [==============================] - 0s 405us/step - loss: 0.0043\n",
            "Epoch 94/300\n",
            "165/165 [==============================] - 0s 410us/step - loss: 0.0045\n",
            "Epoch 95/300\n",
            "165/165 [==============================] - 0s 404us/step - loss: 0.0053\n",
            "Epoch 96/300\n",
            "165/165 [==============================] - 0s 397us/step - loss: 0.0051\n",
            "Epoch 97/300\n",
            "165/165 [==============================] - 0s 403us/step - loss: 0.0050\n",
            "Epoch 98/300\n",
            "165/165 [==============================] - 0s 412us/step - loss: 0.0045\n",
            "Epoch 99/300\n",
            "165/165 [==============================] - 0s 408us/step - loss: 0.0046\n",
            "Epoch 100/300\n",
            "165/165 [==============================] - 0s 382us/step - loss: 0.0047\n",
            "Epoch 101/300\n",
            "165/165 [==============================] - 0s 437us/step - loss: 0.0042\n",
            "Epoch 102/300\n",
            "165/165 [==============================] - 0s 491us/step - loss: 0.0046\n",
            "Epoch 103/300\n",
            "165/165 [==============================] - 0s 408us/step - loss: 0.0043\n",
            "Epoch 104/300\n",
            "165/165 [==============================] - 0s 414us/step - loss: 0.0047\n",
            "Epoch 105/300\n",
            "165/165 [==============================] - 0s 413us/step - loss: 0.0040\n",
            "Epoch 106/300\n",
            "165/165 [==============================] - 0s 421us/step - loss: 0.0047\n",
            "Epoch 107/300\n",
            "165/165 [==============================] - 0s 398us/step - loss: 0.0042\n",
            "Epoch 108/300\n",
            "165/165 [==============================] - 0s 418us/step - loss: 0.0047\n",
            "Epoch 109/300\n",
            "165/165 [==============================] - 0s 418us/step - loss: 0.0048\n",
            "Epoch 110/300\n",
            "165/165 [==============================] - 0s 405us/step - loss: 0.0046\n",
            "Epoch 111/300\n",
            "165/165 [==============================] - 0s 436us/step - loss: 0.0046\n",
            "Epoch 112/300\n",
            "165/165 [==============================] - 0s 413us/step - loss: 0.0042\n",
            "Epoch 113/300\n",
            "165/165 [==============================] - 0s 424us/step - loss: 0.0046\n",
            "Epoch 114/300\n",
            "165/165 [==============================] - 0s 391us/step - loss: 0.0053\n",
            "Epoch 115/300\n",
            "165/165 [==============================] - 0s 425us/step - loss: 0.0042\n",
            "Epoch 116/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0051\n",
            "Epoch 117/300\n",
            "165/165 [==============================] - 0s 489us/step - loss: 0.0048\n",
            "Epoch 118/300\n",
            "165/165 [==============================] - 0s 422us/step - loss: 0.0050\n",
            "Epoch 119/300\n",
            "165/165 [==============================] - 0s 416us/step - loss: 0.0045\n",
            "Epoch 120/300\n",
            "165/165 [==============================] - 0s 408us/step - loss: 0.0043\n",
            "Epoch 121/300\n",
            "165/165 [==============================] - 0s 402us/step - loss: 0.0038\n",
            "Epoch 122/300\n",
            "165/165 [==============================] - 0s 404us/step - loss: 0.0040\n",
            "Epoch 123/300\n",
            "165/165 [==============================] - 0s 411us/step - loss: 0.0047\n",
            "Epoch 124/300\n",
            "165/165 [==============================] - 0s 382us/step - loss: 0.0051\n",
            "Epoch 125/300\n",
            "165/165 [==============================] - 0s 398us/step - loss: 0.0045\n",
            "Epoch 126/300\n",
            "165/165 [==============================] - 0s 411us/step - loss: 0.0046\n",
            "Epoch 127/300\n",
            "165/165 [==============================] - 0s 439us/step - loss: 0.0043\n",
            "Epoch 128/300\n",
            "165/165 [==============================] - 0s 378us/step - loss: 0.0054\n",
            "Epoch 129/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0040\n",
            "Epoch 130/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0045\n",
            "Epoch 131/300\n",
            "165/165 [==============================] - 0s 391us/step - loss: 0.0033\n",
            "Epoch 132/300\n",
            "165/165 [==============================] - 0s 432us/step - loss: 0.0039\n",
            "Epoch 133/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0049\n",
            "Epoch 134/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0035\n",
            "Epoch 135/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0044\n",
            "Epoch 136/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0046\n",
            "Epoch 137/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0052\n",
            "Epoch 138/300\n",
            "165/165 [==============================] - 0s 396us/step - loss: 0.0045\n",
            "Epoch 139/300\n",
            "165/165 [==============================] - 0s 369us/step - loss: 0.0046\n",
            "Epoch 140/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0038\n",
            "Epoch 141/300\n",
            "165/165 [==============================] - 0s 352us/step - loss: 0.0046\n",
            "Epoch 142/300\n",
            "165/165 [==============================] - 0s 359us/step - loss: 0.0038\n",
            "Epoch 143/300\n",
            "165/165 [==============================] - 0s 353us/step - loss: 0.0038\n",
            "Epoch 144/300\n",
            "165/165 [==============================] - 0s 368us/step - loss: 0.0038\n",
            "Epoch 145/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0039\n",
            "Epoch 146/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0042\n",
            "Epoch 147/300\n",
            "165/165 [==============================] - 0s 443us/step - loss: 0.0037\n",
            "Epoch 148/300\n",
            "165/165 [==============================] - 0s 428us/step - loss: 0.0043\n",
            "Epoch 149/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0049\n",
            "Epoch 150/300\n",
            "165/165 [==============================] - 0s 348us/step - loss: 0.0046\n",
            "Epoch 151/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0037\n",
            "Epoch 152/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0045\n",
            "Epoch 153/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0046\n",
            "Epoch 154/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0043\n",
            "Epoch 155/300\n",
            "165/165 [==============================] - 0s 381us/step - loss: 0.0041\n",
            "Epoch 156/300\n",
            "165/165 [==============================] - 0s 359us/step - loss: 0.0041\n",
            "Epoch 157/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0044\n",
            "Epoch 158/300\n",
            "165/165 [==============================] - 0s 347us/step - loss: 0.0043\n",
            "Epoch 159/300\n",
            "165/165 [==============================] - 0s 360us/step - loss: 0.0043\n",
            "Epoch 160/300\n",
            "165/165 [==============================] - 0s 360us/step - loss: 0.0037\n",
            "Epoch 161/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0041\n",
            "Epoch 162/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0046\n",
            "Epoch 163/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0037\n",
            "Epoch 164/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0040\n",
            "Epoch 165/300\n",
            "165/165 [==============================] - 0s 420us/step - loss: 0.0043\n",
            "Epoch 166/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0044\n",
            "Epoch 167/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0042\n",
            "Epoch 168/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0032\n",
            "Epoch 169/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0036\n",
            "Epoch 170/300\n",
            "165/165 [==============================] - 0s 368us/step - loss: 0.0037\n",
            "Epoch 171/300\n",
            "165/165 [==============================] - 0s 372us/step - loss: 0.0036\n",
            "Epoch 172/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0037\n",
            "Epoch 173/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0040\n",
            "Epoch 174/300\n",
            "165/165 [==============================] - 0s 357us/step - loss: 0.0038\n",
            "Epoch 175/300\n",
            "165/165 [==============================] - 0s 388us/step - loss: 0.0036\n",
            "Epoch 176/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0048\n",
            "Epoch 177/300\n",
            "165/165 [==============================] - 0s 357us/step - loss: 0.0044\n",
            "Epoch 178/300\n",
            "165/165 [==============================] - 0s 393us/step - loss: 0.0032\n",
            "Epoch 179/300\n",
            "165/165 [==============================] - 0s 394us/step - loss: 0.0038\n",
            "Epoch 180/300\n",
            "165/165 [==============================] - 0s 365us/step - loss: 0.0039\n",
            "Epoch 181/300\n",
            "165/165 [==============================] - 0s 436us/step - loss: 0.0036\n",
            "Epoch 182/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0037\n",
            "Epoch 183/300\n",
            "165/165 [==============================] - 0s 357us/step - loss: 0.0037\n",
            "Epoch 184/300\n",
            "165/165 [==============================] - 0s 372us/step - loss: 0.0036\n",
            "Epoch 185/300\n",
            "165/165 [==============================] - 0s 348us/step - loss: 0.0037\n",
            "Epoch 186/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0037\n",
            "Epoch 187/300\n",
            "165/165 [==============================] - 0s 378us/step - loss: 0.0037\n",
            "Epoch 188/300\n",
            "165/165 [==============================] - 0s 359us/step - loss: 0.0035\n",
            "Epoch 189/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0037\n",
            "Epoch 190/300\n",
            "165/165 [==============================] - 0s 368us/step - loss: 0.0040\n",
            "Epoch 191/300\n",
            "165/165 [==============================] - 0s 388us/step - loss: 0.0036\n",
            "Epoch 192/300\n",
            "165/165 [==============================] - 0s 374us/step - loss: 0.0034\n",
            "Epoch 193/300\n",
            "165/165 [==============================] - 0s 344us/step - loss: 0.0046\n",
            "Epoch 194/300\n",
            "165/165 [==============================] - 0s 410us/step - loss: 0.0040\n",
            "Epoch 195/300\n",
            "165/165 [==============================] - 0s 399us/step - loss: 0.0040\n",
            "Epoch 196/300\n",
            "165/165 [==============================] - 0s 380us/step - loss: 0.0045\n",
            "Epoch 197/300\n",
            "165/165 [==============================] - 0s 412us/step - loss: 0.0030\n",
            "Epoch 198/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0042\n",
            "Epoch 199/300\n",
            "165/165 [==============================] - 0s 353us/step - loss: 0.0031\n",
            "Epoch 200/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0034\n",
            "Epoch 201/300\n",
            "165/165 [==============================] - 0s 351us/step - loss: 0.0033\n",
            "Epoch 202/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0040\n",
            "Epoch 203/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0032\n",
            "Epoch 204/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0032\n",
            "Epoch 205/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0037\n",
            "Epoch 206/300\n",
            "165/165 [==============================] - 0s 357us/step - loss: 0.0040\n",
            "Epoch 207/300\n",
            "165/165 [==============================] - 0s 374us/step - loss: 0.0041\n",
            "Epoch 208/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0035\n",
            "Epoch 209/300\n",
            "165/165 [==============================] - 0s 375us/step - loss: 0.0035\n",
            "Epoch 210/300\n",
            "165/165 [==============================] - 0s 351us/step - loss: 0.0038\n",
            "Epoch 211/300\n",
            "165/165 [==============================] - 0s 365us/step - loss: 0.0040\n",
            "Epoch 212/300\n",
            "165/165 [==============================] - 0s 378us/step - loss: 0.0036\n",
            "Epoch 213/300\n",
            "165/165 [==============================] - 0s 378us/step - loss: 0.0036\n",
            "Epoch 214/300\n",
            "165/165 [==============================] - 0s 414us/step - loss: 0.0034\n",
            "Epoch 215/300\n",
            "165/165 [==============================] - 0s 360us/step - loss: 0.0036\n",
            "Epoch 216/300\n",
            "165/165 [==============================] - 0s 351us/step - loss: 0.0038\n",
            "Epoch 217/300\n",
            "165/165 [==============================] - 0s 349us/step - loss: 0.0036\n",
            "Epoch 218/300\n",
            "165/165 [==============================] - 0s 372us/step - loss: 0.0034\n",
            "Epoch 219/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0037\n",
            "Epoch 220/300\n",
            "165/165 [==============================] - 0s 365us/step - loss: 0.0038\n",
            "Epoch 221/300\n",
            "165/165 [==============================] - 0s 376us/step - loss: 0.0040\n",
            "Epoch 222/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0032\n",
            "Epoch 223/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0038\n",
            "Epoch 224/300\n",
            "165/165 [==============================] - 0s 405us/step - loss: 0.0036\n",
            "Epoch 225/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0035\n",
            "Epoch 226/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0033\n",
            "Epoch 227/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0036\n",
            "Epoch 228/300\n",
            "165/165 [==============================] - 0s 420us/step - loss: 0.0038\n",
            "Epoch 229/300\n",
            "165/165 [==============================] - 0s 373us/step - loss: 0.0035\n",
            "Epoch 230/300\n",
            "165/165 [==============================] - 0s 430us/step - loss: 0.0040\n",
            "Epoch 231/300\n",
            "165/165 [==============================] - 0s 345us/step - loss: 0.0032\n",
            "Epoch 232/300\n",
            "165/165 [==============================] - 0s 391us/step - loss: 0.0033\n",
            "Epoch 233/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0028\n",
            "Epoch 234/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0034\n",
            "Epoch 235/300\n",
            "165/165 [==============================] - 0s 391us/step - loss: 0.0040\n",
            "Epoch 236/300\n",
            "165/165 [==============================] - 0s 357us/step - loss: 0.0038\n",
            "Epoch 237/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0036\n",
            "Epoch 238/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0031\n",
            "Epoch 239/300\n",
            "165/165 [==============================] - 0s 385us/step - loss: 0.0037\n",
            "Epoch 240/300\n",
            "165/165 [==============================] - 0s 401us/step - loss: 0.0040\n",
            "Epoch 241/300\n",
            "165/165 [==============================] - 0s 400us/step - loss: 0.0037\n",
            "Epoch 242/300\n",
            "165/165 [==============================] - 0s 400us/step - loss: 0.0033\n",
            "Epoch 243/300\n",
            "165/165 [==============================] - 0s 382us/step - loss: 0.0033\n",
            "Epoch 244/300\n",
            "165/165 [==============================] - 0s 374us/step - loss: 0.0036\n",
            "Epoch 245/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0035\n",
            "Epoch 246/300\n",
            "165/165 [==============================] - 0s 409us/step - loss: 0.0029\n",
            "Epoch 247/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0033\n",
            "Epoch 248/300\n",
            "165/165 [==============================] - 0s 369us/step - loss: 0.0035\n",
            "Epoch 249/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0037\n",
            "Epoch 250/300\n",
            "165/165 [==============================] - 0s 353us/step - loss: 0.0026\n",
            "Epoch 251/300\n",
            "165/165 [==============================] - 0s 382us/step - loss: 0.0032\n",
            "Epoch 252/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0037\n",
            "Epoch 253/300\n",
            "165/165 [==============================] - 0s 362us/step - loss: 0.0032\n",
            "Epoch 254/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0032\n",
            "Epoch 255/300\n",
            "165/165 [==============================] - 0s 365us/step - loss: 0.0035\n",
            "Epoch 256/300\n",
            "165/165 [==============================] - 0s 380us/step - loss: 0.0031\n",
            "Epoch 257/300\n",
            "165/165 [==============================] - 0s 374us/step - loss: 0.0034\n",
            "Epoch 258/300\n",
            "165/165 [==============================] - 0s 377us/step - loss: 0.0034\n",
            "Epoch 259/300\n",
            "165/165 [==============================] - 0s 371us/step - loss: 0.0035\n",
            "Epoch 260/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0039\n",
            "Epoch 261/300\n",
            "165/165 [==============================] - 0s 386us/step - loss: 0.0038\n",
            "Epoch 262/300\n",
            "165/165 [==============================] - 0s 379us/step - loss: 0.0033\n",
            "Epoch 263/300\n",
            "165/165 [==============================] - 0s 384us/step - loss: 0.0039\n",
            "Epoch 264/300\n",
            "165/165 [==============================] - 0s 398us/step - loss: 0.0037\n",
            "Epoch 265/300\n",
            "165/165 [==============================] - 0s 359us/step - loss: 0.0032\n",
            "Epoch 266/300\n",
            "165/165 [==============================] - 0s 366us/step - loss: 0.0032\n",
            "Epoch 267/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0043\n",
            "Epoch 268/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0030\n",
            "Epoch 269/300\n",
            "165/165 [==============================] - 0s 368us/step - loss: 0.0030\n",
            "Epoch 270/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0032\n",
            "Epoch 271/300\n",
            "165/165 [==============================] - 0s 349us/step - loss: 0.0029\n",
            "Epoch 272/300\n",
            "165/165 [==============================] - 0s 367us/step - loss: 0.0029\n",
            "Epoch 273/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0032\n",
            "Epoch 274/300\n",
            "165/165 [==============================] - 0s 359us/step - loss: 0.0039\n",
            "Epoch 275/300\n",
            "165/165 [==============================] - 0s 378us/step - loss: 0.0033\n",
            "Epoch 276/300\n",
            "165/165 [==============================] - 0s 367us/step - loss: 0.0029\n",
            "Epoch 277/300\n",
            "165/165 [==============================] - 0s 367us/step - loss: 0.0033\n",
            "Epoch 278/300\n",
            "165/165 [==============================] - 0s 358us/step - loss: 0.0029\n",
            "Epoch 279/300\n",
            "165/165 [==============================] - 0s 432us/step - loss: 0.0035\n",
            "Epoch 280/300\n",
            "165/165 [==============================] - 0s 361us/step - loss: 0.0030\n",
            "Epoch 281/300\n",
            "165/165 [==============================] - 0s 356us/step - loss: 0.0037\n",
            "Epoch 282/300\n",
            "165/165 [==============================] - 0s 352us/step - loss: 0.0029\n",
            "Epoch 283/300\n",
            "165/165 [==============================] - 0s 388us/step - loss: 0.0032\n",
            "Epoch 284/300\n",
            "165/165 [==============================] - 0s 363us/step - loss: 0.0031\n",
            "Epoch 285/300\n",
            "165/165 [==============================] - 0s 377us/step - loss: 0.0030\n",
            "Epoch 286/300\n",
            "165/165 [==============================] - 0s 379us/step - loss: 0.0029\n",
            "Epoch 287/300\n",
            "165/165 [==============================] - 0s 348us/step - loss: 0.0031\n",
            "Epoch 288/300\n",
            "165/165 [==============================] - 0s 365us/step - loss: 0.0032\n",
            "Epoch 289/300\n",
            "165/165 [==============================] - 0s 355us/step - loss: 0.0038\n",
            "Epoch 290/300\n",
            "165/165 [==============================] - 0s 384us/step - loss: 0.0031\n",
            "Epoch 291/300\n",
            "165/165 [==============================] - 0s 370us/step - loss: 0.0027\n",
            "Epoch 292/300\n",
            "165/165 [==============================] - 0s 360us/step - loss: 0.0032\n",
            "Epoch 293/300\n",
            "165/165 [==============================] - 0s 374us/step - loss: 0.0024\n",
            "Epoch 294/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0032\n",
            "Epoch 295/300\n",
            "165/165 [==============================] - 0s 384us/step - loss: 0.0028\n",
            "Epoch 296/300\n",
            "165/165 [==============================] - 0s 401us/step - loss: 0.0033\n",
            "Epoch 297/300\n",
            "165/165 [==============================] - 0s 364us/step - loss: 0.0030\n",
            "Epoch 298/300\n",
            "165/165 [==============================] - 0s 372us/step - loss: 0.0030\n",
            "Epoch 299/300\n",
            "165/165 [==============================] - 0s 377us/step - loss: 0.0032\n",
            "Epoch 300/300\n",
            "165/165 [==============================] - 0s 351us/step - loss: 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb_5jrXmR11D",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVsAS_V7QkY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_val = model.predict(X_val)\n",
        "diff = []\n",
        "for i in range(len(y_val)):\n",
        "    pred = preds_val[i][0]\n",
        "    diff.append(y_val[i] - pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhij8Wg3QkVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b2f2b5e-3f54-43f3-dd6e-d9567e30fb2b"
      },
      "source": [
        "preds_val[0][0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9660213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOkAOrbDSh-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05ca7575-9117-4aff-d0cd-e8155537a5a3"
      },
      "source": [
        "y_val[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9950432826389483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX0TmZLiUXgs",
        "colab_type": "text"
      },
      "source": [
        "### Convert the predict back to original meaning (before MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlERVzPmTSaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f54c876d-f89a-45fe-bd1b-a5a7f532b5c1"
      },
      "source": [
        "real_min = preprocessor.data_min_[104]\n",
        "real_max = preprocessor.data_max_[104]\n",
        "\n",
        "print(preprocessor.data_min_[104])\n",
        "print(preprocessor.data_max_[104])\n",
        "\n",
        "preds_real = preds_val * (real_max - real_min) + real_min\n",
        "y_val_real = y_val * (real_max - real_min) + real_min"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1172.060059\n",
            "5128.279785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAX6Z1_YTSXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6a9e66fa-4cc4-4b9c-fb16-27b0e0a752ad"
      },
      "source": [
        "plt.plot(preds_real, label='Predictions')\n",
        "plt.plot(y_val_real, label='Actual values')\n",
        "plt.xlabel('test')\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFruHwoUluxsvwjRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngsBYoB8UsPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}