{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizing_with_batch_nomalization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminDKLuong/Colab_Notes/blob/master/Optimizing_with_batch_nomalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZqGzhzcnzi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d72f53e1-aeb7-47e1-a5b8-7516655c1888"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_-bnTWuJ5lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a209201a-a80d-4d07-d8e9-952d43dbd0ee"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_val, y_val) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 44s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtDnia3VK0TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')/255.\n",
        "X_val = X_val.astype('float32')/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrscyVQaKFkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_val = np_utils.to_categorical(y_val, n_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC5nqslSKFhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1085
        },
        "outputId": "5fc68422-934b-48fe-e945-e1a8597b692c"
      },
      "source": [
        "input_shape = X_train[0].shape\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,403,050\n",
            "Trainable params: 1,403,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZoKu8lNgOZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_acc', patience=5, verbose=1)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxF2E7fNgOcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "n_epochs = 300\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq2ky3dfgOfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1512
        },
        "outputId": "5bdc1a5d-68e3-41fb-e09b-bcb0bab1138d"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=batch_size, \n",
        "                    epochs=n_epochs, verbose=1, \n",
        "                    validation_data=(X_val, y_val), \n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.8514 - acc: 0.3075 - val_loss: 1.5491 - val_acc: 0.4248\n",
            "Epoch 2/300\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.4057 - acc: 0.4849 - val_loss: 1.2154 - val_acc: 0.5608\n",
            "Epoch 3/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.1821 - acc: 0.5732 - val_loss: 1.0547 - val_acc: 0.6160\n",
            "Epoch 4/300\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.0301 - acc: 0.6311 - val_loss: 0.9518 - val_acc: 0.6623\n",
            "Epoch 5/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.9346 - acc: 0.6676 - val_loss: 0.8595 - val_acc: 0.6975\n",
            "Epoch 6/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.8534 - acc: 0.6988 - val_loss: 0.8581 - val_acc: 0.6955\n",
            "Epoch 7/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.7972 - acc: 0.7202 - val_loss: 0.7284 - val_acc: 0.7459\n",
            "Epoch 8/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.7387 - acc: 0.7395 - val_loss: 0.6890 - val_acc: 0.7601\n",
            "Epoch 9/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6929 - acc: 0.7564 - val_loss: 0.6668 - val_acc: 0.7694\n",
            "Epoch 10/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.6542 - acc: 0.7694 - val_loss: 0.6676 - val_acc: 0.7695\n",
            "Epoch 11/300\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.6224 - acc: 0.7815 - val_loss: 0.6883 - val_acc: 0.7652\n",
            "Epoch 12/300\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 0.5827 - acc: 0.7949 - val_loss: 0.6548 - val_acc: 0.7758\n",
            "Epoch 13/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.5621 - acc: 0.8007 - val_loss: 0.6179 - val_acc: 0.7913\n",
            "Epoch 14/300\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.5359 - acc: 0.8105 - val_loss: 0.6268 - val_acc: 0.7847\n",
            "Epoch 15/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.5232 - acc: 0.8163 - val_loss: 0.5986 - val_acc: 0.7943\n",
            "Epoch 16/300\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.4998 - acc: 0.8238 - val_loss: 0.5822 - val_acc: 0.8034\n",
            "Epoch 17/300\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.4764 - acc: 0.8322 - val_loss: 0.5657 - val_acc: 0.8105\n",
            "Epoch 18/300\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.4594 - acc: 0.8358 - val_loss: 0.5756 - val_acc: 0.8101\n",
            "Epoch 19/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.4463 - acc: 0.8432 - val_loss: 0.5980 - val_acc: 0.8072\n",
            "Epoch 20/300\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.4292 - acc: 0.8471 - val_loss: 0.5753 - val_acc: 0.8118\n",
            "Epoch 21/300\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4160 - acc: 0.8532 - val_loss: 0.5550 - val_acc: 0.8195\n",
            "Epoch 22/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.4098 - acc: 0.8549 - val_loss: 0.5612 - val_acc: 0.8204\n",
            "Epoch 23/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.3832 - acc: 0.8638 - val_loss: 0.5594 - val_acc: 0.8197\n",
            "Epoch 24/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.3825 - acc: 0.8655 - val_loss: 0.5844 - val_acc: 0.8122\n",
            "Epoch 25/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.3692 - acc: 0.8682 - val_loss: 0.5689 - val_acc: 0.8212\n",
            "Epoch 26/300\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.3597 - acc: 0.8732 - val_loss: 0.5671 - val_acc: 0.8184\n",
            "Epoch 27/300\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.3485 - acc: 0.8756 - val_loss: 0.5679 - val_acc: 0.8227\n",
            "Epoch 28/300\n",
            "50000/50000 [==============================] - 6s 120us/step - loss: 0.3474 - acc: 0.8769 - val_loss: 0.5546 - val_acc: 0.8270\n",
            "Epoch 29/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.3380 - acc: 0.8786 - val_loss: 0.5653 - val_acc: 0.8215\n",
            "Epoch 30/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.3252 - acc: 0.8846 - val_loss: 0.5661 - val_acc: 0.8247\n",
            "Epoch 31/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.3238 - acc: 0.8848 - val_loss: 0.5623 - val_acc: 0.8191\n",
            "Epoch 32/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.3162 - acc: 0.8878 - val_loss: 0.6001 - val_acc: 0.8177\n",
            "Epoch 33/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.3105 - acc: 0.8906 - val_loss: 0.5538 - val_acc: 0.8304\n",
            "Epoch 34/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.3003 - acc: 0.8945 - val_loss: 0.5596 - val_acc: 0.8307\n",
            "Epoch 35/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.2903 - acc: 0.8968 - val_loss: 0.6049 - val_acc: 0.8155\n",
            "Epoch 36/300\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3023 - acc: 0.8928 - val_loss: 0.5629 - val_acc: 0.8278\n",
            "Epoch 37/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.2872 - acc: 0.8972 - val_loss: 0.5896 - val_acc: 0.8165\n",
            "Epoch 38/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.2788 - acc: 0.9017 - val_loss: 0.6057 - val_acc: 0.8248\n",
            "Epoch 39/300\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 0.2802 - acc: 0.9000 - val_loss: 0.5905 - val_acc: 0.8208\n",
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR7m41CogXxJ",
        "colab_type": "text"
      },
      "source": [
        "# Model with BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRyOajq4gOt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        },
        "outputId": "106321ce-bbb2-4d1b-81b3-781489e31ca1"
      },
      "source": [
        "model_bn = Sequential()\n",
        "\n",
        "model_bn.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model_bn.add(Dropout(0.25))\n",
        "\n",
        "model_bn.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model_bn.add(Dropout(0.25))\n",
        "\n",
        "model_bn.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model_bn.add(Dropout(0.25))\n",
        "\n",
        "model_bn.add(Flatten())\n",
        "model_bn.add(Dense(512, activation='relu'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Dropout(0.5))\n",
        "model_bn.add(Dense(128, activation='relu'))\n",
        "model_bn.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "model_bn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_bn.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,406,890\n",
            "Trainable params: 1,404,970\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n26V_pDEZrq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1210
        },
        "outputId": "c2c9717d-b978-4ea3-ff11-9c923f07c1f5"
      },
      "source": [
        "history_bn = model_bn.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=n_epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val), callbacks=callbacks)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 1.6558 - acc: 0.4239 - val_loss: 1.7074 - val_acc: 0.4462\n",
            "Epoch 2/300\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 1.1838 - acc: 0.5749 - val_loss: 1.0633 - val_acc: 0.6248\n",
            "Epoch 3/300\n",
            "50000/50000 [==============================] - 8s 165us/step - loss: 0.9567 - acc: 0.6587 - val_loss: 0.8732 - val_acc: 0.6981\n",
            "Epoch 4/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.8158 - acc: 0.7138 - val_loss: 0.7851 - val_acc: 0.7268\n",
            "Epoch 5/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.7321 - acc: 0.7404 - val_loss: 0.7354 - val_acc: 0.7476\n",
            "Epoch 6/300\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 0.6705 - acc: 0.7632 - val_loss: 0.7348 - val_acc: 0.7501\n",
            "Epoch 7/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.6192 - acc: 0.7819 - val_loss: 0.6512 - val_acc: 0.7755\n",
            "Epoch 8/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.5764 - acc: 0.7968 - val_loss: 0.6280 - val_acc: 0.7854\n",
            "Epoch 9/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.5328 - acc: 0.8140 - val_loss: 0.6796 - val_acc: 0.7709\n",
            "Epoch 10/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.4988 - acc: 0.8238 - val_loss: 0.5888 - val_acc: 0.8009\n",
            "Epoch 11/300\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.4668 - acc: 0.8342 - val_loss: 0.5574 - val_acc: 0.8112\n",
            "Epoch 12/300\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.4434 - acc: 0.8446 - val_loss: 0.5893 - val_acc: 0.8085\n",
            "Epoch 13/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.4171 - acc: 0.8537 - val_loss: 0.5730 - val_acc: 0.8125\n",
            "Epoch 14/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.3945 - acc: 0.8621 - val_loss: 0.5429 - val_acc: 0.8216\n",
            "Epoch 15/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.3680 - acc: 0.8703 - val_loss: 0.5301 - val_acc: 0.8273\n",
            "Epoch 16/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.3508 - acc: 0.8764 - val_loss: 0.5156 - val_acc: 0.8324\n",
            "Epoch 17/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.3364 - acc: 0.8813 - val_loss: 0.5541 - val_acc: 0.8239\n",
            "Epoch 18/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.3170 - acc: 0.8866 - val_loss: 0.5215 - val_acc: 0.8378\n",
            "Epoch 19/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.3066 - acc: 0.8894 - val_loss: 0.5529 - val_acc: 0.8244\n",
            "Epoch 20/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.2904 - acc: 0.8966 - val_loss: 0.5319 - val_acc: 0.8384\n",
            "Epoch 21/300\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 0.2707 - acc: 0.9027 - val_loss: 0.6690 - val_acc: 0.8004\n",
            "Epoch 22/300\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.2675 - acc: 0.9045 - val_loss: 0.5270 - val_acc: 0.8371\n",
            "Epoch 23/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.2561 - acc: 0.9087 - val_loss: 0.5544 - val_acc: 0.8365\n",
            "Epoch 24/300\n",
            "50000/50000 [==============================] - 8s 165us/step - loss: 0.2404 - acc: 0.9133 - val_loss: 0.5338 - val_acc: 0.8462\n",
            "Epoch 25/300\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.2308 - acc: 0.9186 - val_loss: 0.5280 - val_acc: 0.8471\n",
            "Epoch 26/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.2226 - acc: 0.9215 - val_loss: 0.5422 - val_acc: 0.8425\n",
            "Epoch 27/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.2218 - acc: 0.9206 - val_loss: 0.4946 - val_acc: 0.8545\n",
            "Epoch 28/300\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.2090 - acc: 0.9247 - val_loss: 0.5277 - val_acc: 0.8487\n",
            "Epoch 29/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.1999 - acc: 0.9277 - val_loss: 0.5211 - val_acc: 0.8514\n",
            "Epoch 30/300\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.1988 - acc: 0.9279 - val_loss: 0.5409 - val_acc: 0.8482\n",
            "Epoch 31/300\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 0.1911 - acc: 0.9315 - val_loss: 0.5182 - val_acc: 0.8536\n",
            "Epoch 32/300\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.1776 - acc: 0.9367 - val_loss: 0.5599 - val_acc: 0.8479\n",
            "Epoch 00032: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk8KFbevgniR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "33d796d5-4d65-44db-89d9-62140e4a47f3"
      },
      "source": [
        "val_acc_bn = history_bn.history['val_acc']\n",
        "val_acc = history.history['val_acc']\n",
        "plt.plot(range(len(val_acc)), val_acc, label='CNN model')\n",
        "plt.plot(range(len(val_acc_bn)), val_acc_bn, label='CNN model with BN')\n",
        "plt.title('Validation accuracy on Cifar10 dataset')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobATK_Jgney",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "411acf69-c21c-4255-cc1d-e769751c75dd"
      },
      "source": [
        "print(max(val_acc_bn), max(val_acc))\n",
        "print(len(val_acc_bn), len(val_acc))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8545 0.8307\n",
            "32 39\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}